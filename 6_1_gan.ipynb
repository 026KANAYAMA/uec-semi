{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d90a102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.datasets as dst\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# seed\n",
    "seed = 0\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06066a06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yanai-lab/kanayama-r/.conda/envs/myenv/lib/python3.10/site-packages/torchvision/transforms/v2/_deprecated.py:42: UserWarning: The transform `ToTensor()` is deprecated and will be removed in a future release. Instead, please use `v2.Compose([v2.ToImage(), v2.ToDtype(torch.float32, scale=True)])`.Output is equivalent up to float precision.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# settings\n",
    "batch_size = 128*4 # 512\n",
    "\n",
    "# data\n",
    "dataroot = \"/export/space0/kanayama-r/semi/uec-semi/data/CelebA/Img\"\n",
    "\n",
    "def only_img_celeba(path):\n",
    "    # dirname(path) の basename が \"img_celeba\" だけ通す\n",
    "    return os.path.basename(os.path.dirname(path)) == \"img_celeba\"\n",
    "\n",
    "dataset = dst.ImageFolder(\n",
    "    root=dataroot,\n",
    "    transform=v2.Compose([\n",
    "        v2.CenterCrop(178),\n",
    "        v2.Resize(28),\n",
    "        v2.Grayscale(num_output_channels=1),\n",
    "        v2.ToTensor(),\n",
    "        # v2.Normalize([0.5]*3, [0.5]*3) # [-1,1] に正規化（GANの場合多い）\n",
    "        v2.Normalize([0.5], [0.5])\n",
    "    ]),\n",
    "    is_valid_file=only_img_celeba,\n",
    "    allow_empty=True,  \n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=4,\n",
    "    pin_memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f274e263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "202599"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a499ebcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module): # nn.Moduleは継承しなくてもいいけど一応\n",
    "    def __init__(self, z_dim=100, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(z_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, img_dim),\n",
    "            nn.Tanh() # range[-1,1]\n",
    "        )\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, img_dim=28*28):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(img_dim, 256),\n",
    "            nn.LeakyReLU(0.2, True), # Dが早く飽和して学習しなくなるのを防ぐ\n",
    "            nn.Linear(256, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce3e14e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss_D: 0.621, loss_G: 1.900\n",
      "epoch: 2, loss_D: 0.475, loss_G: 1.716\n"
     ]
    }
   ],
   "source": [
    "# exp\n",
    "G = nn.DataParallel(Generator()).to(device)\n",
    "D = nn.DataParallel(Discriminator()).to(device)\n",
    "\n",
    "opt_G = torch.optim.Adam(G.parameters(), lr=2e-4)\n",
    "opt_D = torch.optim.Adam(D.parameters(), lr=2e-4)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "# ノイズ\n",
    "z = torch.randn(batch_size, 100, device=device)\n",
    "\n",
    "# learning\n",
    "epochs = 100\n",
    "z_dim = 100\n",
    "for epoch in range(epochs):\n",
    "    total_loss_D = 0\n",
    "    total_loss_G = 0\n",
    "    for real_imgs, _ in dataloader:\n",
    "        real = real_imgs.view(real_imgs.size(0), -1).to(device) #[b,img_dim]\n",
    "\n",
    "        # 1.Discriminator更新\n",
    "        D.zero_grad()\n",
    "        real_labels = torch.ones(real.size(0),1, device=device) #本物ラベル\n",
    "        pred_real = D(real)\n",
    "        loss_real = criterion(pred_real, real_labels)\n",
    "\n",
    "        # 偽物生成\n",
    "        z = torch.randn(real.size(0), z_dim, device=device)\n",
    "        fake = G(z).detach()\n",
    "        fake_labels = torch.zeros(real.size(0),1, device=device)\n",
    "        pred_fake = D(fake)\n",
    "        loss_fake = criterion(pred_fake, fake_labels)\n",
    "\n",
    "        loss_D = loss_real + loss_fake\n",
    "        loss_D.backward()\n",
    "        opt_D.step()\n",
    "        total_loss_D += loss_D\n",
    "\n",
    "        # 2.Generator更新\n",
    "        G.zero_grad()\n",
    "        z2 = torch.randn(real.size(0), z_dim, device=device)\n",
    "        fake2 = G(z2)\n",
    "        pred2 = D(fake2)\n",
    "        loss_G = criterion(pred2, torch.ones_like(pred2))\n",
    "        loss_G.backward()\n",
    "        opt_G.step()\n",
    "        total_loss_G += loss_G\n",
    "\n",
    "    avg_loss_D = total_loss_D / len(dataloader)\n",
    "    avg_loss_G = total_loss_G / len(dataloader)\n",
    "    print(f\"epoch: {epoch+1}, loss_D: {avg_loss_D:.3f}, loss_G: {avg_loss_G:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0940c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 検証\n",
    "G.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "502f6109",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1161876/3898387827.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  G.load_state_dict(torch.load(\"6_1_gan.pth\", map_location=device))\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 読み込み\n",
    "G = Generator(z_dim=100, img_dim=28*28).to(device)\n",
    "G.load_state_dict(torch.load(\"6_1_gan.pth\", map_location=device))\n",
    "G = nn.DataParallel(G)\n",
    "\n",
    "# 検証\n",
    "G.eval()\n",
    "with torch.no_grad():\n",
    "    z = torch.randn(1, 100, device=device)\n",
    "    fake_imgs = G(z)                # → Tensor [16, img_dim]\n",
    "    fake_imgs = fake_imgs.view(1, 1, 28, 28)\n",
    "    fake_imgs = fake_imgs[0,0].cpu().numpy()\n",
    "\n",
    "# 可視化\n",
    "plt.imshow(fake_imgs, cmap='gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efbfef8c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
