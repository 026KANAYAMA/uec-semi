{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33e4c472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0,1,2,3\"\n",
    "import time\n",
    "import random\n",
    "import glob\n",
    "from PIL import Image\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "from torch.multiprocessing.spawn import spawn\n",
    "import torchvision.models as models\n",
    "import torchvision.datasets as dst\n",
    "from torchvision.io import read_image\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5429f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_image(img):\n",
    "    transforms = v2.Compose([\n",
    "        v2.ToTensor(), \n",
    "        v2.ToDtype(torch.float32, scale=True),\n",
    "    ])\n",
    "    return transforms(img)\n",
    "\n",
    "test_dataset = dst.CIFAR10(\n",
    "    root=\"../data\",\n",
    "    train=False,\n",
    "    download=False,\n",
    "    transform=transform_image\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dd910924",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.size>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset[0][0].size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40c985e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbdb4ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "986339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dim=256):\n",
    "        super().__init__()\n",
    "        # conv 層で次第にチャネル数↑・空間サイズ↓\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, 4, 2, 1),  # 32→16\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(64, 128, 4, 2, 1), # 16→8\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv2d(128, 256, 4, 2, 1),# 8→4\n",
    "            nn.ReLU(True),\n",
    "        )\n",
    "        self.fc = nn.Linear(256*4*4, bottleneck_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.conv(x)\n",
    "        h_flat = h.view(x.size(0), -1)\n",
    "        z = self.fc(h_flat)\n",
    "        return z, h  # ボトルネックと中間マップを返す\n",
    "    \n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dim=256):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(bottleneck_dim, 256*4*4)\n",
    "        self.deconv = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, 4, 2, 1), # 4→8\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(128, 64, 4, 2, 1),  # 8→16\n",
    "            nn.ReLU(True),\n",
    "            nn.ConvTranspose2d(64, 3, 4, 2, 1),    # 16→32\n",
    "            nn.Sigmoid(),  # 出力を [0,1] に\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        h = self.fc(z)\n",
    "        h = h.view(z.size(0), 256, 4, 4)\n",
    "        x_recon = self.deconv(h)\n",
    "        return x_recon\n",
    "    \n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, bottleneck_dim=256):\n",
    "        super().__init__()\n",
    "        self.encoder = Encoder(bottleneck_dim)\n",
    "        self.decoder = Decoder(bottleneck_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        z, h = self.encoder(x)\n",
    "        x_recon = self.decoder(z)\n",
    "        return x_recon, z, h\n",
    "    \n",
    "# full_sd = torch.load(\"./1_autoencoder.pth\", map_location=device)\n",
    "full_sd = torch.load(\"./1_2_denoising_ae.pth\", map_location=device)\n",
    "\n",
    "# 2) encoder 部分だけフィルタしてプレフィックスを除去\n",
    "encoder_sd = {\n",
    "    k.replace(\"encoder.\", \"\"): v\n",
    "    for k, v in full_sd.items()\n",
    "    if k.startswith(\"encoder.\")\n",
    "}\n",
    "\n",
    "# 3) Encoder モデルを作ってロード\n",
    "encoder = Encoder(bottleneck_dim=256)\n",
    "encoder.load_state_dict(encoder_sd)\n",
    "encoder = nn.DataParallel(encoder.to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d996672",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(test_dataset, batch_size=100, shuffle=False)\n",
    "\n",
    "encoder.eval()\n",
    "with torch.no_grad():\n",
    "    imgs, labels = next(iter(dataloader))\n",
    "    imgs = imgs.to(device)\n",
    "    # 中間特徴マップを取得\n",
    "    z, h = encoder(imgs)\n",
    "    # h: [100, 256, 4, 4] → flatten → [100, 256*4*4]\n",
    "    feats = h.view(h.size(0), -1).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d100cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- k = 5 ---\n",
      "Cluster     0   1  2   3  4\n",
      "airplane    0   3  0   4  3\n",
      "automobile  1   1  2   1  1\n",
      "bird        0   5  0   1  2\n",
      "cat         0   7  2   1  0\n",
      "deer        0   6  0   1  0\n",
      "dog         0   5  0   3  0\n",
      "frog        0  11  4   1  0\n",
      "horse       0   3  2   3  3\n",
      "ship        1   3  0   2  7\n",
      "truck       0   1  0  10  0\n",
      "--- k = 10 ---\n",
      "Cluster     0  1  2  3   4  5  6  7  8  9\n",
      "airplane    0  5  1  0   1  2  1  0  0  0\n",
      "automobile  1  2  0  1   1  0  0  0  0  1\n",
      "bird        0  3  1  0   2  0  2  0  0  0\n",
      "cat         0  2  1  2   5  0  0  0  0  0\n",
      "deer        0  4  0  0   2  0  1  0  0  0\n",
      "dog         0  2  0  0   2  0  2  2  0  0\n",
      "frog        0  2  0  1  11  0  0  2  0  0\n",
      "horse       0  1  3  1   1  0  0  4  0  1\n",
      "ship        1  6  6  0   0  0  0  0  0  0\n",
      "truck       1  4  0  0   0  0  4  1  1  0\n"
     ]
    }
   ],
   "source": [
    "classes = ['airplane','automobile','bird','cat','deer','dog','frog','horse','ship','truck']\n",
    "for k in (5, 10):\n",
    "    kmeans = KMeans(n_clusters=k, random_state=0).fit(feats)\n",
    "    cluster_labels = kmeans.labels_\n",
    "\n",
    "    # 真のラベルごとにクラスタ分布を集計\n",
    "    df = pd.crosstab(pd.Series(labels, name='TrueLabel'),\n",
    "                    pd.Series(cluster_labels, name='Cluster'))\n",
    "    # インデックスをラベル名に変換\n",
    "    df.index = [classes[i] for i in df.index]\n",
    "\n",
    "    print(f\"--- k = {k} ---\")\n",
    "    print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23e9ed7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
